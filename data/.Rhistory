z<-matrix(NA, nrow=length(p.f1.v2),ncol=length(v1))
for(i in 1:length(p.f1.v2)) {
for(j in 1:length(v1)){
#v11<- v1[j] #v1 # you need to either do this inside the equations below or:
#v1 <- v1[j]
v2<-1-v1[j] #2
first<-v1[i]*0.05+v1[i]*0.4
second<-v2*p.f1.v2[i]+v2*0.05
z[i,j]<-first+second # you are also not indexing here to step through your output matrix
}
}
z
p.F1.V1 <- 0.05 # P(F1|V1)
p.F2.V1 <- 0.4
p.F2.V2 <- 0.05
p.V1 <- seq(from = 0.001, to = 1, len = 100) # P(V2)
p.V2 <- 1 - p.V1
p.F1 <- matrix(nrow = 100, ncol = 4)
p.F2 <- matrix(nrow = 100, ncol = 4)
p.F1.V2 <- seq(from = 0.2, to = 0.8, len = 4) # P(F1), P(F2)
for (j in 1:4) {
p.F1[, j] <- p.F1.V1 * p.V1 + p.F1.V2[j] * p.V2
p.F2[, j] <- p.F2.V1 * p.V1 + p.F2.V2 * p.V2
}
p.F1 + p.F2
z<-matrix(NA, nrow=length(p.f1.v2),ncol=length(v1))
for(i in 1:length(p.f1.v2)) {
for(j in 1:length(v1)){
#v1[j] #v1 # you need to either do this inside the equations below
v2<-1-v1[j] #2
first<-v1[i]*0.05+v1[i]*0.4
second<-(1-v1[j])*p.f1.v2[i]+(1-v1[j])*0.05
z[i,j]<-first+second # you are also not indexing here to step through your output matrix
}
}
z
plot(j,z[,0.2],type=" l",xlab="FDR",ylim=c(0,1),main="Total Prevelence of Flu", ylab="Prob That Has Flu given diagnosis",col="blue", lty=1)
lines(j,z[,0.4],xlab="FDR",ylab="Prob That Has Flu given diagnosis", col="purple")
lines(j,z[,0.6],xlab="FDR",ylab="Prob That Has Flu given diagnosis", col="darkseagreen2")
lines(j,z[,0.8],xlab="FDR",ylab="Prob That Has Flu given diagnosis", col="deeppink4")
p.D.F2 <- 0.7
p.F2 <- seq(from = 0.2, to = 0.8, len = 4)
p.D.not.F2 <- seq(from = 0.01, to = 0.5, len = 100)
p.F2.D <- matrix(nrow = length(p.F2), ncol = length(p.D.not.F2)) for (i in 1:length(p.F2)) {
for (j in 1:length(p.D.not.F2)) {
p.F2.D[i, j] <- (p.D.F2 * p.F2[i])/(p.D.F2 * p.F2[i] +
p.D.not.F2[j] * (1 - p.F2[i])) }
}
p.F2.D <- matrix(nrow = length(p.F2), ncol = length(p.D.not.F2))
for (i in 1:length(p.F2)) {
for (j in 1:length(p.D.not.F2)) {
p.F2.D[i, j] <- (p.D.F2 * p.F2[i])/(p.D.F2 * p.F2[i] +
p.D.not.F2[j] * (1 - p.F2[i]))
}
}
p.F2.D
p.F1.V1 <- 0.05 # P(F1|V1)
# P(F2|V1)
p.F2.V1 <- 0.4
# P(F2|V2)
p.F2.V2 <- 0.05
# P(V1)
p.V1 <- seq(from = 0.001, to = 1, len = 100) # P(V2)
p.V2 <- 1 - p.V1
# P(F1)
p.F1 <- matrix(nrow = 100, ncol = 4)
# P(F2)
p.F2 <- matrix(nrow = 100, ncol = 4)
# P(F1|V2)
p.F1.V2 <- seq(from = 0.2, to = 0.8, len = 4) # P(F1), P(F2)
for (j in 1:4) {
p.F1[, j] <- p.F1.V1 * p.V1 + p.F1.V2[j] * p.V2
p.F2[, j] <- p.F2.V1 * p.V1 + p.F2.V2 * p.V2
}
p.F1+p.F2
p.D.F2 <- 0.7
p.F2 <- seq(from = 0.2, to = 0.8, len = 4)
p.D.not.F2 <- seq(from = 0.01, to = 0.5, len = 100)
p.F2.D <- matrix(nrow = length(p.F2), ncol = length(p.D.not.F2))
for (i in 1:length(p.F2)) {
for (j in 1:length(p.D.not.F2)) {
p.F2.D[i, j] <- (p.D.F2 * p.F2[i])/(p.D.F2 * p.F2[i] +
p.D.not.F2[j] * (1 - p.F2[i]))
}
}
p.F2.D
d1 <- read.csv(file = "http://faraway.neu.edu/data/assn1_dataset1.csv")
fluii<- subset(d1, subset=age<18|age>65)
flui<-subset(d1, subset=age>=18 & age<=65)
fluiiag<-aggregate(age~flu,FUN=length,data=fluii)
fluiag<-aggregate(age~flu,FUN=length,data=flui)
dfi<-data.frame(fluiag$age,fluiiag$age)
rownames(dfi)<-c("Swine","Seasonal")
names(dfi)<-sub("^fluiiag.age$", "Old/Young", names(dfi))
names(dfi)<-sub("^fluiag.age$", "Middle Aged", names(dfi))
dfi
PF1gV1<- .05
PF2gV1<- .4
PF2gV2<- .05
PF2gnV2<-1-PF2gV2
PF1gV2<- seq(.2, .8, by= .2)
PF1gV2
PF1gnV2<- 1-PF1gV2
PV1<- seq(.001, 1, length.out = 100)
PV2<- 1-PV1
PF1<- ((PV2*PF1gV2)+(PV1*PF1gnV2))
PF1
P.F2<- ((PV2*PF2gV2)+(PV1*PF2gnV2))
P.F2
vaccF1_matrix<- matrix(nrow = length(PV1), ncol = length(PF1gV2))
for(i in 1:nrow(vaccF1_matrix)){
for(j in 1:ncol(vaccF1_matrix)){
PF1<- ((PV2[i]*PF1gV2[j])+(PV1[i]*PF1gnV2[j]))
vaccF1_matrix[i, j]<- PF1
}
}
vaccF1_matrix
vaccF2_matrix<- matrix(nrow = length(PV1), ncol = length(PF2gV2))
for(i in 1:nrow(vaccF2_matrix)){
for(j in 1:ncol(vaccF2_matrix)){
PF2<- ((PV2[i]*PF2gV2[j])+(PV1[i]*PF2gnV2[j]))
vaccF2_matrix[i, j]<- PF2
}
}
vaccF2_matrix
vaccF1_matrix
vacc_matrix<- vaccF1_matrix*vaccF1_matrix
vacc_matrix
vaccF1_matrix<- matrix(nrow = length(PV1), ncol = length(PF1gV2))
for(i in 1:nrow(vaccF1_matrix)){
for(j in 1:ncol(vaccF1_matrix)){
PF1<- ((PV2[i]*PF1gV2[j])+(PV1[i]*PF1gnV2[j]))
vaccF1_matrix[i, j]<- PF1
}
}
midage <- subset(d1, age >= 18 & age <= 65)
endage <- subset(d1, age < 18 | age > 65)
agegroup <- c(midage, endage)
a1 <- aggregate(age~flu, FUN = length, data = midage)
a2 <- aggregate(age~flu, FUN = length, data = endage)
a3 <- c(a1, a2)
df1 <- data.frame(a1, a2)
df1
p.D.F2 <- 0.7
p.F2 <- seq(from = 0.2, to = 0.8, len = 4)
p.D.not.F2 <- seq(from = 0.01, to = 0.5, len = 100)
p.F2.D <- matrix(nrow = length(p.F2), ncol = length(p.D.not.F2))
for (i in 1:length(p.F2)) {
for (j in 1:length(p.D.not.F2)) {
p.F2.D[i, j] <- (p.D.F2 * p.F2[i])/(p.D.F2 * p.F2[i] +
p.D.not.F2[j] * (1 - p.F2[i]))
}
}
p.F1.V1 <- 0.05 # P(F1|V1)
# P(F2|V1)
p.F2.V1 <- 0.4
# P(F2|V2)
p.F2.V2 <- 0.05
# P(V1)
p.V1 <- seq(from = 0.001, to = 1, len = 100) # P(V2)
p.V2 <- 1 - p.V1
# P(F1)
p.F1 <- matrix(nrow = 100, ncol = 4)
# P(F2)
p.F2 <- matrix(nrow = 100, ncol = 4)
# P(F1|V2)
p.F1.V2 <- seq(from = 0.2, to = 0.8, len = 4) # P(F1), P(F2)
for (j in 1:4) {
p.F1[, j] <- p.F1.V1 * p.V1 + p.F1.V2[j] * p.V2
p.F2[, j] <- p.F2.V1 * p.V1 + p.F2.V2 * p.V2
}
p.F1+p.F2
.95*0.6
x <- rnorm(1000)
qqnorm(x)
qqline(x, col = "red")
x <- rlnorm(1000)
qqnorm(x)
qqline(x, col = "red")
d1 <- read.csv("http://faraway.neu.edu/data/lab4_dataset1.csv")
hist(d1$age, xlab = "Ages", main = "")
par(mfrow = c(2, 1))
hist(d1$age, xlab = "Ages", main = "Raw ages")
hist(log10(d1$age), xlab = "Ages", main = "log10-transformed ages")
control.age <- subset(d1, treatment == "control", select = "age")
vaccinated.age <- subset(d1, treatment == "vaccinated", select = "age")
t.test(control.age, vaccinated.age)
hist(d1$score, main = "", xlab = "HPV score")
dev.off()
hist(d1$score, main = "", xlab = "HPV score")
qqnorm(d1$score)
qqline(d1$score, col = "red")
qqnorm(log10(d1$score))
qqline(log10(d1$score), col = "red")
control <- log10(subset(d1, treatment == "control", select = "score"))
vaccinated <- log10(subset(d1, treatment == "vaccinated", select = "score"))
t.test(control, vaccinated)
(mean.score <- aggregate(score ~ treatment, data = d1, FUN = mean))
mean.score <- aggregate(score ~ treatment, data = d1, FUN = mean)
stderr.score <- aggregate(score ~ treatment, data = d1, FUN = function(x) sd(x)/sqrt(length(x)))
mean.score <- aggregate(score ~ treatment, data = d1, FUN = mean)
mean.score <- aggregate(score ~ treatment, data = d1, FUN = length)
mean.score <- aggregate(score ~ treatment, data = d1, FUN = mean)
head(d1)
sapply(score~treatment, data = d1, FUN = mean)
mean()
?mean
ci.upp <- mean.score$score + 1.96 * stderr.score$score
ci.low <- mean.score$score - 1.96 * stderr.score$score
bp <- barplot(mean.score$score, names = mean.score$treatment,
ylim = c(0, max(ci.upp + 1.9)), ylab = "HPV score")
arrows(y0 = ci.low, y1 = ci.upp, x0 = bp, x1 = bp, angle = 90, code = 3,
length = 0.1)
text(x = bp, y = ci.upp, c("a", "b"), pos = 3)
bp <- barplot(mean.score$score, names = mean.score$treatment,
ylim = c(0, max(ci.upp + 5)), ylab = "HPV score")
arrows(y0 = ci.low, y1 = ci.upp, x0 = bp, x1 = bp, angle = 90, code = 3,
length = 0.1)
text(x = bp, y = ci.upp, c("a", "b"), pos = 3)
bp <- barplot(mean.score$score, names = mean.score$treatment,
ylim = c(0, 70), ylab = "HPV score")
arrows(y0 = ci.low, y1 = ci.upp, x0 = bp, x1 = bp, angle = 90, code = 3,
length = 0.1)
text(x = bp, y = ci.upp, c("a", "b"), pos = 3)
mean.score <- aggregate(score ~ treatment, data = d1, FUN = mean)
View(mean)
rm(mean)
mean.score <- aggregate(score ~ treatment, data = d1, FUN = mean)
ci.upp <- mean.score$score + 1.96 * stderr.score$score
ci.low <- mean.score$score - 1.96 * stderr.score$score
bp <- barplot(mean.score$score, names = mean.score$treatment,
ylim = c(0, 70), ylab = "HPV score")
arrows(y0 = ci.low, y1 = ci.upp, x0 = bp, x1 = bp, angle = 90, code = 3,
length = 0.1)
text(x = bp, y = ci.upp, c("a", "b"), pos = 3)
bp <- barplot(mean.score$score, names = mean.score$treatment,
ylim = c(0, 30), ylab = "HPV score")
bp <- barplot(mean.score$score, names = mean.score$treatment,
ylim = c(0, 20), ylab = "HPV score")
arrows(y0 = ci.low, y1 = ci.upp, x0 = bp, x1 = bp, angle = 90, code = 3,
length = 0.1)
text(x = bp, y = ci.upp, c("a", "b"), pos = 3)
mean.score
d2 <- read.csv("http://faraway.neu.edu/data/lab4_dataset2.csv")
a <- aggregate(score ~ treatment + trial, data = d2, FUN = mean)
ratio <- a$score[seq(from = 1, to = NROW(a), by = 2)]/a$score[seq(from = 2,
to = NROW(a), by = 2)]
t.test(ratio, mu = mean.score[1, 2]/mean.score[2, 2])
var(vaccinated.age$age)
var(control.age)
hist(d1$age, xlab = "Ages", main = "")
qqnorm(d1$age)
qqline(d1$age, col = "red")
control.age
t.test(control.age, vaccinated.age)
ratio <- a$score[seq(from = 1, to = NROW(a), by = 2)]/a$score[seq(from = 2,
to = NROW(a), by = 2)]
ratio
t.test(ratio, mu = mean.score[1, 2]/mean.score[2, 2])
ratio
mean.score[1, 2]/mean.score[2, 2]
seq(from = 1, to = NROW(a), by = 2)
z
a
ratio.fun <- function(x){
x[1]/x[2]
}
aggregate(score~trial, data = a, FUN = ratio.fun)
c <- subset(d1, subset = treatment == "control")
t <- subset(d1, subset = treatment == "vaccinated")
dataa <- cbind(c,t)
dataa
dataa <- cbind(c$score,t$score)
dataa
sapply(dataa, FUN = sterr)
sterr <- function(x){
sd(x)/sqrt(length(x))
}
sapply(dataa, FUN = sterr)
my.vars <- data.frame(a1 = 1:10, a2 = 11:20, b1 = 21:30, b2 = 31:40)
my.vars
my.means <- sapply(my.vars, FUN = mean)
my.means
my.means <- sapply(my.vars, FUN = sterr)
my.means
my.means <- sapply(my.vars, FUN = mean)
sapply(dataa, FUN = sterr)
sapply(dataa, FUN = mean)
dataa
dataa <- as.data.frame(cbind(c$score,t$score))
sapply(dataa, FUN = mean)
sapply(dataa, FUN = sterr)
data <- c(0.98, 0.87, 1.1, 0.88, 0.85, 0.93, 0.95)
t.test(data, mu = 2)
t.test(data, mu = 1)
(.944-2)/(0.08886/sqrt(7))
(.944-2)/(0.8886/sqrt(7))
(.944-2)/(0.008886/sqrt(7))
2.4469-(0.08886/sqrt(7))
2.4469*(0.08886/sqrt(7))
0.944-2.4469*(0.08886/sqrt(7))
0.98+0.87+1.1+0.88+0.85+0.93+1
(0.98+0.87+1.1+0.88+0.85+0.93+1)/7
sqrt(224)
sqrt(224/6)
6*0.089/1.237
.085/sqrt(7)
6*0.0079/1.237
.088/sqrt(7)
.088/sqrt(7)*12
.088/sqrt(7)*2.44
sd(data)
.107^2
.088/sqrt(7)
.085/sqrt(7)
0.056(.085/sqrt(7))
0.056/(.085/sqrt(7))
2.44*0.0336
2.44*0.0336 + .9183
2.44*0.0336 - .9183
sd(data)
sqrt((1/6)*0.0691)
(.98-1)^2 + (.87-1)^2 + (1.1-1)^2 + (.88-1)^2 + (.85-1)^2 + (.93-1)^2
6*(0.088)^2/1.237
2.44*0.78 + .9183
.9183-2.44*0.0336
.944-2.44*0.0336
.944-2.44*0.78
sqrt((1/6)*0.064)
(.98-1)^2
.98-1
.98-.944
(.98-.944)^2
(.87-.944)^2
(1.1-.944)^2
(.88-0.944)^2
(.85-0.944)^2
(.93-0.944)^2
(.98-.944)^2 + (.87-.944)^2 + (1.1-.944)^2 + (.88-0.944)^2 + (.85-0.944)^2 + (.93-0.944)^2 + (1-0.944)^2
(.98-.944)^2 + (.87-.944)^2 + (1.1-.944)^2 + (.88-0.944)^2 + (.85-0.944)^2 + (.93-0.944)^2 +
(1-0.944)^2
(1-0.944)^2
(.944-1)/(0.08886/sqrt(7))
(0.08886/sqrt(7))
(.944-1)
(.944-1)/(0.08886/sqrt(7))
(.944-1)/(0.089/sqrt(7))
(.94-1)/(0.089/sqrt(7))
(.87-.944)^2
(1.1-.944)^2
(.88-0.944)^2
(1-0.944)^2
(.98-.944)^2
(.98-.944)^2 + (.87-.944)^2 + (1.1-.944)^2 + (.88-0.944)^2 + (.85-0.944)^2 + (.93-0.944)^2 + (1-0.944)^2
sd(data)
sd(data)^2
0.0926^2
0.0926^2*6/1.237
sd(data)*6/1.237
0.089/sqrt(7)
0.088/sqrt(7)
benguela <- read.csv("http://faraway.neu.edu/data/assn3_benguela.csv")
b.time <- (ifelse(benguela$year>=2025, yes = "after", no = "before"))
b.time
length(75)
benguela <- read.csv("http://faraway.neu.edu/data/assn3_benguela.csv")
benguela <- read.csv("http://faraway.neu.edu/data/assn3_benguela.csv")
california <- read.csv("http://faraway.neu.edu/data/assn3_california.csv")
#Assignment Question 1
benguela$period <- ifelse(benguela$year >= 1950 & benguela$year <= 2024,"before","after")
california$period <- ifelse(california$year >= 1950 & california$year <= 2024,"before","after")
canary$period <- ifelse(canary$year >= 1950 & canary$year <= 2024,"before","after")
humboldt$period <- ifelse(humboldt$year >= 1950 & humboldt$year <= 2024,"before","after")
#This adds before and after descriptors to the existing datasets, separating rows into either from 1950-2024(before) or 2050-2099(after).
head(benguela) #updated benguela preview top
tail(benguela)# updated beanguel preview bottom
head(california) #updated california preview top
tail(california) #updated california preview bottom
head(canary) #updated preview top
tail(canary)#updated preview bottom
head(humboldt) #updated humboldt preview top
tail(humboldt) #updated canary preview bottom
benmean <- data.frame(benguela$year,benguela$period,rowMeans(benguela[1:150,1:22]))
colnames(benmean) <- c("year","period","Multi-model-Mean")
benguela <- read.csv("http://faraway.neu.edu/data/assn3_benguela.csv")
california <- read.csv("http://faraway.neu.edu/data/assn3_california.csv")
canary <- read.csv("http://faraway.neu.edu/data/assn3_canary.csv")
humboldt <- read.csv("http://faraway.neu.edu/data/assn3_humboldt.csv")
#Assignment Question 1
benguela$period <- ifelse(benguela$year >= 1950 & benguela$year <= 2024,"before","after")
california$period <- ifelse(california$year >= 1950 & california$year <= 2024,"before","after")
canary$period <- ifelse(canary$year >= 1950 & canary$year <= 2024,"before","after")
humboldt$period <- ifelse(humboldt$year >= 1950 & humboldt$year <= 2024,"before","after")
#This adds before and after descriptors to the existing datasets, separating rows into either from 1950-2024(before) or 2050-2099(after).
head(benguela) #updated benguela preview top
tail(benguela)# updated beanguel preview bottom
head(california) #updated california preview top
tail(california) #updated california preview bottom
head(canary) #updated preview top
tail(canary)#updated preview bottom
head(humboldt) #updated humboldt preview top
tail(humboldt) #updated canary preview bottom
#Assignment question 2
# Adds multi-model mean vector Benguela
benmean <- data.frame(benguela$year,benguela$period,rowMeans(benguela[1:150,1:22]))
colnames(benmean) <- c("year","period","Multi-model-Mean")
benmean
#Adds multi-model mean vector california
calmean <- data.frame(california$year,california$period,rowMeans(california[1:150,1:22]))
colnames(calmean) <- c("year","period","Multi-model-Mean")
calmean
# Adds multi-model mean vector Canary
canmean <- data.frame(canary$year,canary$period,rowMeans(canary[1:150,1:22]))
colnames(canmean) <- c("year","period","Multi-model-Mean")
canmean
# Adds multi-model mean vector Humbdolt
hummean <- data.frame(humboldt$year,humboldt$period,rowMeans(humboldt[1:150,1:22]))
colnames(hummean) <- c("year","period","Multi-model-Mean")
hummean
#Each data frame is then given the multi-model mean by taking the average of each row.
# Question 3
#The before and after periods are isolated for each location of interests
benbefore <- subset(benmean,subset = period == "before")
benafter <-  subset(benmean,subset = period == "after")
calbefore <- subset(calmean,subset = period == "before")
calafter <-  subset(calmean,subset = period == "after")
canbefore <- subset(canmean,subset = period == "before")
canafter <-  subset(canmean,subset = period == "after")
humbefore <- subset(hummean,subset = period == "before")
humafter <-  subset(hummean,subset = period == "after")
# Histograms for before and after periods. Shapiro tests are run for each period to statistically determine normality for each period in each EBCS.
#Shapiro Ho: The distribution of data in both periods in each EBCS is normal.
#Shapiro Ha: The distribution of data in both period in each EBCS is not normal.
hist(benbefore$Multi, main = "Benguela Multi-Model mean 1950 - 2024",breaks = 20,xlab = "Multi-model Mean")
shapiro.test(benbefore$Multi)
#Since the p-value is greater than .05 we fail to reject the null hypothesis, therefore the data is normally distributed.
hist(benafter$Multi, main = "Benguela Multi-Model mean 2025 - 2099", xlab = "Multi-model Mean", breaks = 20)
#Appears bimodal
shapiro.test(benafter$Multi)
#Since the p-value is greater than .05 we fail to reject the null hypothesis therefore the data is normally distributed, despite the histogram appearing be bimodel by eye.
hist(calbefore$Multi, main = "california Multi-Model mean 1950 - 2024",breaks = 20,xlab = "Multi-model Mean") # close to normal california
shapiro.test(calbefore$Multi)
#Numerical validation for california before
#Since the P-value is greater than .05 we fail to reject the null hypothesis, therefore the data is normally distributed
hist(calafter$Multi, main = "california Multi-Model mean 2025 - 2099",breaks = 20,xlab = "Multi-model Mean") # close to normal california
shapiro.test(calafter$Multi)
#Numerical Validation for california after
#Since the p-value is greater than .05 we fail to reject the null hypothesis, therefore the data is normally distributed
hist(canbefore$Multi, main = "Canary Multi-Model mean 1950 - 2024",breaks = 20,xlab = "Multi-model mean") # close to normal Canary
shapiro.test(canbefore$Multi)
#Numerical validation for Canary before
# Since the p-value, is greater than .05 we fail to reject the null hypothesis the before the data is normal.
hist(canafter$Multi, main = "Canary Multi-Model mean 2025 - 2099", breaks = 20,xlab = "Multi-model mean") # not normal, right skewed Canary
shapiro.test(canafter$Multi)
#Numerical validation for Canary after
#Since the p-value is less than .05 we reject the null hypothesis and conclude that the data is normal.
hist(humbefore$Multi, main = "Humboldt Multi-Model mean 1950 - 2024",breaks = 20,xlab = "Multi-model Mean") # not normal, left skewed Canary
shapiro.test(humbefore$Multi)
#Numerical validation for Humboldt
#Since the p-value is above .05, we fail to reject the null hypothesis therefore the the data can be assumed to be normal.
hist(humafter$Multi, main = "Humboldt Multi-model mean 2025 - 2099",breaks = 20,xlab = "Multi-model Mean") # not normal, uniform  Canary
shapiro.test(humafter$Multi)
#Numerical validation for Humboldt
#Since the p-value is below .05 we reject the null hypothesis, the before this data is not normal.
# The drawback to using a non-parametric test is that they are less powerful than parametric test meaning that it's more difficult to reject the null hypothesis. This will only increase if the assumptions of randomly distributed data isn't met.
#P1 Q4
#Assignment 1 P1 Q4
#Null Hyp = The multimodel mean does not differ between periods for each EBCS.
#Alt Hyp = The multimodel differs between periods for each EBCS.
humulti <- hummean$Multi
humulti
calmulti <- calmean$Multi
calmulti
benmulti <- benmean$Multi
benmulti
canmulti <- canmean$Multi
canmulti
shapiro.test(humulti)  #not normal
shapiro.test(calmulti) #normal
shapiro.test(benmulti) #not normal
shapiro.test(canmulti) #not normal
x = rnorm(humbefore$`Multi-model-Mean`)
y = rnorm(humafter$`Multi-model-Mean`)
x1 = rnorm(calbefore$`Multi-model-Mean`)
y1 = rnorm(calafter$`Multi-model-Mean`)
x2 = rnorm(benbefore$`Multi-model-Mean`)
y2 = rnorm(benafter$`Multi-model-Mean`)
x3 = rnorm(canbefore$`Multi-model-Mean`)
y3 = rnorm(canafter$`Multi-model-Mean`)
#run non-parametric test
wilcox.test(x,y) #Humbolt
wilcox.test(x1,y1) #California
wilcox.test(x2,y2) #Benguela
wilcox.test(x3,y3) #Canary
#We run a Mann-Whitney U t-test to substitute a two sample t-test because our data is not normal. We fail to reject the null and conclude that the evidence suggests multimodel mean does not differ significantly between periods.
x
head(benguela) #updated benguela preview top
tail(benguela)# updated beanguel preview bottom
head(benmean)
tail(benmean)
hummean$Multi
getwd()
setwd("~/Documents/Northeastern/LotterhosLab/Research/Iceland/data")
read.csv("~/cod_sara_A12-2018.xlsx")
read.csv("/cod_sara_A12-2018.xlsx")
read.csv("./cod_sara_A12-2018.xlsx")
wrong  <- read.csv("./cod_sara_A12-2018.xlsx")
get(wd)
getwd()
wrong  <- read.csv2("./cod_sara_A12-2018.xlsx", header = TRUE, sep = ";")
wrong  <- read.csv2("./cod_sara_A12-2018.csv", header = TRUE, sep = ";")
head(wrong)
